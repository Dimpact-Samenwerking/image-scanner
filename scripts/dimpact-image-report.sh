#!/usr/bin/env bash

# Dimpact Image Scanner - Report Generator
# This script generates consolidated reports from existing SARIF scan results
# Can be run standalone to generate reports from previous scans
# Includes dashboard data preparation for GitHub Pages deployment

set -e

# Ensure we're using bash
if [ -z "${BASH_VERSION:-}" ]; then
    echo "Error: This script requires bash" >&2
    exit 1
fi

# Check bash version
if (( BASH_VERSINFO[0] < 4 )); then
    echo "Warning: This script works best with bash 4.0 or later" >&2
    echo "Current version: $BASH_VERSION" >&2
    echo "On macOS, you can upgrade with: brew install bash" >&2
fi

# Colors for output (only use colors if not in CI environment)
if [ -z "${CI:-}" ]; then
    RED='\033[0;31m'
    GREEN='\033[0;32m'
    YELLOW='\033[1;33m'
    BLUE='\033[0;34m'
    NC='\033[0m' # No Color
else
    RED=''
    GREEN=''
    YELLOW=''
    BLUE=''
    NC=''
fi

# Default configuration
# Create date-prefixed input directory (YYMMDD format)
DEFAULT_DATE_PREFIX=$(date +%y%m%d)
INPUT_DIR="${INPUT_DIR:-./dimpact-scan-results/${DEFAULT_DATE_PREFIX}}"
CVE_SUPPRESSIONS_FILE="${CVE_SUPPRESSIONS_FILE:-cve-suppressions.md}"

# Declare array for suppressed CVEs
declare -a suppressed_cves

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --input-dir)
            INPUT_DIR="$2"
            shift 2
            ;;
        --cve-suppressions)
            CVE_SUPPRESSIONS_FILE="$2"
            shift 2
            ;;
        --test)
            # Use test data for prototyping
            INPUT_DIR="test-data/sample-scan-results"
            CVE_SUPPRESSIONS_FILE="test-data/cve-suppressions.md"
            TEST_MODE=true
            shift
            ;;
        -h|--help)
            echo "Usage: $0 [OPTIONS]"
            echo ""
            echo "Options:"
            echo "  --input-dir DIR          Directory containing scan results"
            echo "                           (default: ./dimpact-scan-results/YYMMDD)"
            echo "  --cve-suppressions FILE  CVE suppressions file"
            echo "                           (default: cve-suppressions.md)"
            echo "  --test                   Use built-in test data for prototyping"
            echo "  --help                   Show this help message"
            echo ""
            echo "Description:"
            echo "  Generates a consolidated security report from SARIF scan results"
            echo "  and automatically updates the dashboard data for GitHub Pages."
            echo "  The input directory should contain subdirectories with"
            echo "  trivy-results.sarif files generated by the scanner."
            echo ""
            echo "Dashboard Update:"
            echo "  The script automatically prepares data for GitHub Pages deployment"
            echo "  by copying SARIF files to docs/data/. This enables the security"
            echo "  dashboard to work on GitHub Pages without any additional steps."
            echo ""
            echo "Examples:"
            echo "  $0 --input-dir ./my-scan-results"
            echo "  $0 --input-dir ./results"
            echo "  $0 --test                                # Use built-in sample data"
            exit 0
            ;;
        *)
            echo "Unknown option: $1"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
done

# Source utility functions
source "$(dirname "$0")/dimpact-scanner-utils.sh"

# Function to print colored output
print_status() {
    echo -e "${BLUE}ℹ️  [INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}✅ [SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}⚠️  [WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}❌ [ERROR]${NC} $1"
}

# Function to check if a command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to check if script is run from correct location
check_location() {
    if [ ! -f "scripts/$(basename "$0")" ]; then
        print_error "This script must be run from the project root directory"
        print_status "Correct usage: ./scripts/$(basename "$0")"
        exit 1
    fi
}

# Function to update dashboard data for GitHub Pages
update_dashboard_data() {
    print_status "🌐 Updating dashboard data for GitHub Pages..."
    
    # Check location
    check_location
    
    # Validate source directory
    if [ ! -d "$INPUT_DIR" ]; then
        print_error "Source directory '$INPUT_DIR' does not exist"
        return 1
    fi
    
    # Check for SARIF files
    SARIF_COUNT=$(find "$INPUT_DIR" -name "trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
    if [ "$SARIF_COUNT" -eq 0 ]; then
        print_error "No SARIF files found in '$INPUT_DIR'"
        print_status "Expected to find trivy-results.sarif files in subdirectories"
        return 1
    fi
    
    print_success "Found $SARIF_COUNT SARIF files in source directory"
    
    # Create data directory
    print_status "Creating docs/data directory..."
    mkdir -p docs/data
    rm -rf docs/data/* 2>/dev/null || true
    
    # Copy scan results
    print_status "Copying scan results to docs/data/..."
    copied_files=0
    failed_files=0
    
    # Count total directories for progress tracking
    local total_scan_dirs=$(find "$INPUT_DIR" -maxdepth 1 -type d | tail -n +2 | wc -l | tr -d ' ')
    local current_scan_dir=0
    
    for scan_dir in "$INPUT_DIR"/*/; do
        if [ -d "$scan_dir" ]; then
            current_scan_dir=$((current_scan_dir + 1))
            dir_name=$(basename "$scan_dir")
            target_dir="docs/data/$dir_name"
            
            # Show progress for dashboard copy
            print_status "  [$current_scan_dir/$total_scan_dirs] Copying: $dir_name"
            
            # Create target directory
            mkdir -p "$target_dir"
            
            # Copy SARIF file if it exists
            if [ -f "$scan_dir/trivy-results.sarif" ]; then
                if cp "$scan_dir/trivy-results.sarif" "$target_dir/" 2>/dev/null; then
                    copied_files=$((copied_files + 1))
                    echo "    ✓ SARIF file copied successfully"
                else
                    failed_files=$((failed_files + 1))
                    echo "    ✗ SARIF file copy failed"
                fi
            else
                echo "    ⚠ No SARIF file found"
            fi
        fi
    done
    
    # Report results
    echo ""
    print_success "Dashboard data update completed:"
    total_dirs=$(find "$INPUT_DIR" -maxdepth 1 -type d | wc -l | tr -d ' ')
    total_dirs=$((total_dirs - 1))  # Subtract 1 for the parent directory itself
    echo "  📊 Total directories processed: $total_dirs"
    echo "  ✅ Successfully copied: $copied_files SARIF files"
    if [ "$failed_files" -gt 0 ]; then
        echo "  ❌ Failed copies: $failed_files files"
    fi
    
    # Verify data structure
    print_status "Verifying data structure..."
    total_sarif=$(find docs/data -name "trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
    total_data_dirs=$(find docs/data -maxdepth 1 -type d | tail -n +2 | wc -l | tr -d ' ')
    
    echo "  📁 Directories in docs/data/: $total_data_dirs"
    echo "  📄 SARIF files: $total_sarif"
    
    # Check for large files (GitHub has 100MB limit)
    large_files=$(find docs/data -name "*.sarif" -size +50M 2>/dev/null || true)
    if [ -n "$large_files" ]; then
        print_warning "Large SARIF files detected (>50MB):"
        echo "$large_files" | while read -r file; do
            size=$(du -h "$file" | cut -f1)
            echo "  📦 $file ($size)"
        done
        echo ""
        print_status "Consider using Git LFS for files >100MB"
    fi
    
    # Generate dashboard update summary
    echo ""
    print_success "🎉 Dashboard data updated successfully!"
    echo ""
    echo "📋 Next steps for GitHub Pages:"
    echo "  1. 📤 git add docs/data/"
    echo "  2. 💾 git commit -m \"📊 Update security dashboard data\""
    echo "  3. 🚀 git push origin main"
    echo "  4. 🌐 Enable GitHub Pages (Settings → Pages → docs folder)"
    echo ""
    print_status "To test locally:"
    echo "  cd docs && python3 -m http.server 8080"
    
    return 0
}

# Function to extract helm chart name from image name
extract_helm_chart() {
    local img_name="$1"
    # Try to extract helm chart name from image name patterns
    # Common patterns: chartname-component, chartname/component, etc.
    local chart_name=""
    
    # Pattern 1: name-component (e.g., wordpress-mysql)
    if [[ "$img_name" =~ ^([a-zA-Z0-9-]+)-[a-zA-Z0-9-]+$ ]]; then
        chart_name="${BASH_REMATCH[1]}"
    # Pattern 2: registry/namespace/chartname (e.g., docker.io/bitnami/wordpress)
    elif [[ "$img_name" =~ /([a-zA-Z0-9-]+)$ ]]; then
        chart_name="${BASH_REMATCH[1]}"
    # Pattern 3: just use the base name if no pattern matches
    else
        chart_name=$(echo "$img_name" | sed 's/[^a-zA-Z0-9-].*$//' | sed 's/-[0-9].*$//')
    fi
    
    echo "${chart_name:-unknown}"
}

# Function to extract actual CVE severity from SARIF rule metadata
extract_cve_severity() {
    local sarif_file="$1"
    local rule_id="$2"
    
    # Try to extract severity from rule properties tags first
    local severity=$(jq -r --arg rule_id "$rule_id" '
    .runs[0].tool.driver.rules[] | 
    select(.id == $rule_id) | 
    .properties.tags[]? | 
    select(. == "CRITICAL" or . == "HIGH" or . == "MEDIUM" or . == "LOW")' "$sarif_file" 2>/dev/null | head -1)
    
    # If not found in tags, try to extract from help text
    if [ -z "$severity" ] || [ "$severity" = "null" ]; then
        severity=$(jq -r --arg rule_id "$rule_id" '
        .runs[0].tool.driver.rules[] | 
        select(.id == $rule_id) | 
        .help.text?' "$sarif_file" 2>/dev/null | grep -o "Severity: [A-Z]*" | cut -d' ' -f2 | head -1)
    fi
    
    # Default to UNKNOWN if not found
    echo "${severity:-UNKNOWN}"
}

# Function to count vulnerabilities by actual CVE severity from SARIF files (optimized)
count_vulnerabilities_by_severity() {
    local img_dir="$1"
    local target_severity="$2"
    
    # Use efficient direct counting from properties.tags
    local count=$(jq -r ".runs[0].tool.driver.rules[] | select(.properties.tags[]? == \"$target_severity\") | .id" "${img_dir}trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
    
    # Fallback to help text if no results from tags
    if [ "$count" = "0" ]; then
        count=$(jq -r ".runs[0].tool.driver.rules[] | select(.help.text? | test(\"Severity: $target_severity\")) | .id" "${img_dir}trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
    fi
    
    echo "${count:-0}"
}

# Function to count vulnerabilities from SARIF files using actual CVE severity
count_vulnerabilities() {
    local img_dir="$1"
    local severity="$2"
    
    count_vulnerabilities_by_severity "$img_dir" "$severity"
}

# Function to extract EPSS analysis for a container
extract_epss_analysis() {
    local img_dir="$1"
    local sarif_file="${img_dir}trivy-results.sarif"
    
    if [ ! -f "$sarif_file" ] || [ ! -s "$sarif_file" ]; then
        return 0
    fi
    
    # Check if SARIF file has EPSS data
    local has_epss=$(jq -r '.runs[0].properties.epss // empty' "$sarif_file" 2>/dev/null)
    if [ -z "$has_epss" ]; then
        return 0
    fi
    
    # Extract EPSS statistics
    local high_risk_count=$(jq -r '.runs[0].properties.epss.high_risk_count // 0' "$sarif_file" 2>/dev/null)
    local very_high_risk_count=$(jq -r '.runs[0].properties.epss.very_high_risk_count // 0' "$sarif_file" 2>/dev/null)
    local total_cves=$(jq -r '.runs[0].properties.epss.total_cves // 0' "$sarif_file" 2>/dev/null)
    local threshold=$(jq -r '.runs[0].properties.epss.threshold // "5%"' "$sarif_file" 2>/dev/null)
    
    if [ "$total_cves" -gt 0 ]; then
        local risk_percentage=$(( (high_risk_count * 100) / total_cves ))
        
        # Format the EPSS analysis output
        local output=""
        output="${output}- **🚨 High-Risk CVEs (EPSS >$threshold):** $high_risk_count\n"
        
        if [ "$very_high_risk_count" -gt 0 ]; then
            output="${output}- **⚠️ Very High-Risk CVEs (>20%):** $very_high_risk_count\n"
            
            # Extract specific very high-risk CVEs
            local very_high_cves=$(jq -r '.runs[0].properties.epss.scores[] | select((.epss | tonumber) > 0.20) | "\(.cve) (\(.epss))"' "$sarif_file" 2>/dev/null | head -3)
            if [ -n "$very_high_cves" ]; then
                output="${output}- **🎯 Top Very High-Risk CVEs:**\n"
                while IFS= read -r cve_info; do
                    output="${output}  - \`$cve_info\`\n"
                done <<< "$very_high_cves"
            fi
        fi
        
        output="${output}- **📊 Exploitation Risk:** $risk_percentage% of CVEs have high exploitation probability"
        
        echo -e "$output"
    fi
}

# Optimized function to count all severities at once
count_all_severities_report() {
    local img_dir="$1"
    
    # Use efficient batch counting from properties.tags
    local critical_count=$(jq -r '.runs[0].tool.driver.rules[] | select(.properties.tags[]? == "CRITICAL") | .id' "${img_dir}trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
    local high_count=$(jq -r '.runs[0].tool.driver.rules[] | select(.properties.tags[]? == "HIGH") | .id' "${img_dir}trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
    local medium_count=$(jq -r '.runs[0].tool.driver.rules[] | select(.properties.tags[]? == "MEDIUM") | .id' "${img_dir}trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
    local low_count=$(jq -r '.runs[0].tool.driver.rules[] | select(.properties.tags[]? == "LOW") | .id' "${img_dir}trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
    
    # Fallback to help text if no results from tags
    if [ "$critical_count" = "0" ] && [ "$high_count" = "0" ] && [ "$medium_count" = "0" ] && [ "$low_count" = "0" ]; then
        critical_count=$(jq -r '.runs[0].tool.driver.rules[] | select(.help.text? | test("Severity: CRITICAL")) | .id' "${img_dir}trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
        high_count=$(jq -r '.runs[0].tool.driver.rules[] | select(.help.text? | test("Severity: HIGH")) | .id' "${img_dir}trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
        medium_count=$(jq -r '.runs[0].tool.driver.rules[] | select(.help.text? | test("Severity: MEDIUM")) | .id' "${img_dir}trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
        low_count=$(jq -r '.runs[0].tool.driver.rules[] | select(.help.text? | test("Severity: LOW")) | .id' "${img_dir}trivy-results.sarif" 2>/dev/null | wc -l | tr -d ' ')
    fi
    
    # Output counts in format: CRITICAL,HIGH,MEDIUM,LOW
    echo "${critical_count:-0},${high_count:-0},${medium_count:-0},${low_count:-0}"
}

# Function to count suppressed vulnerabilities by actual severity from SARIF files
count_suppressed_vulnerabilities_by_severity() {
    local img_dir="$1"
    local suppressed_json="$2"
    local target_severity="$3"
    
    # Get suppressed rule IDs and count those with matching severity
    jq -r --argjson cves "$suppressed_json" '
    [.runs[]?.results[]? | select(.ruleId | IN($cves[]))] | 
    unique_by(.ruleId) | .[].ruleId' "${img_dir}trivy-results.sarif" 2>/dev/null | while read -r rule_id; do
        if [ -n "$rule_id" ]; then
            local severity=$(extract_cve_severity "${img_dir}trivy-results.sarif" "$rule_id")
            if [ "$severity" = "$target_severity" ]; then
                echo "$rule_id"
            fi
        fi
    done | wc -l | tr -d ' '
}

# Function to count suppressed vulnerabilities from SARIF files  
count_suppressed_vulnerabilities() {
    local img_dir="$1"
    local suppressed_json="$2"
    
    # Count all suppressed vulnerabilities (regardless of severity)
    jq -r --argjson cves "$suppressed_json" '
    [.runs[]?.results[]? | select(.ruleId | IN($cves[]))] | 
    length' "${img_dir}trivy-results.sarif" 2>/dev/null || echo 0
}

# Optimized function to generate detailed CVE report using batch processing
generate_detailed_cve_report() {
    local img_name="$1"
    local img_dir="$2"
    local report_file="$3"
    local helm_chart
    helm_chart=$(extract_helm_chart "$img_name")
    
    echo -e "\n### 🖼️ $img_name" >> "$report_file"
    echo "**Helm Chart:** $helm_chart" >> "$report_file"
    echo "" >> "$report_file"
    
    # Create suppressed CVEs JSON for filtering
    local suppressed_json
    suppressed_json=$(printf '%s\n' "${suppressed_cves[@]}" | jq -R . | jq -s .)
    
    # Single optimized jq call to get all vulnerability data with severity, filtering, and details
    local vuln_data=$(jq -r --argjson suppressed_cves "$suppressed_json" '
    # Create lookup objects for rules and results
    def rules_lookup: [.runs[0].tool.driver.rules[]] | group_by(.id) | map({
        id: .[0].id,
        helpUri: (.[0].helpUri // "No reference"),
        severity: (
            (.[0].properties.tags[]? | select(. == "CRITICAL" or . == "HIGH" or . == "MEDIUM" or . == "LOW")) //
            (.[0].help.text? | capture("Severity: (?<sev>[A-Z]+)") | .sev) //
            "UNKNOWN"
        )
    }) | map({(.id): .}) | add;
    
    def results_lookup: [.runs[]?.results[]?] | group_by(.ruleId) | map({
        ruleId: .[0].ruleId,
        message: .[0].message.text,
        location: (.[0].locations[0]?.physicalLocation?.artifactLocation?.uri // "N/A")
    }) | map({(.ruleId): .}) | add;
    
    # Build lookup tables
    rules_lookup as $rules |
    results_lookup as $results |
    
    # Get all unique rule IDs and process them
    [.runs[]?.results[]? | .ruleId] | unique[] |
    select(. != null and . != "") |
    select(. as $id | ($suppressed_cves | index($id)) == null) |  # Filter out suppressed
    . as $rule_id |
    {
        ruleId: $rule_id,
        severity: ($rules[$rule_id].severity // "UNKNOWN"),
        helpUri: ($rules[$rule_id].helpUri // "No reference"),
        message: ($results[$rule_id].message // "No message"),
        location: ($results[$rule_id].location // "N/A")
    } |
    select(.severity != "UNKNOWN") |
    "\(.severity)|\(.ruleId)|\(.message)|\(.location)|\(.helpUri)"
    ' "${img_dir}trivy-results.sarif" 2>/dev/null)
    
    # Process each severity level using the pre-processed data
    for severity in "CRITICAL" "HIGH" "MEDIUM" "LOW"; do
        local severity_emoji=""
        case $severity in
            "CRITICAL") severity_emoji="🔴" ;;
            "HIGH") severity_emoji="🟠" ;;
            "MEDIUM") severity_emoji="🟡" ;;
            "LOW") severity_emoji="🔵" ;;
        esac
        
        # Filter vulnerabilities for this severity level
        local severity_vulns=$(echo "$vuln_data" | grep "^$severity|" || true)
        
        if [ -n "$severity_vulns" ]; then
            local count=$(echo "$severity_vulns" | wc -l | tr -d ' ')
            echo "#### $severity_emoji $severity Vulnerabilities ($count)" >> "$report_file"
            echo "" >> "$report_file"
            
            # Process each vulnerability for this severity level
            while IFS='|' read -r sev rule_id message location help_uri; do
                if [ -n "$rule_id" ]; then
                    echo "**CVE:** $rule_id" >> "$report_file"
                    echo "**Image:** $img_name" >> "$report_file"
                    echo "**Helm Chart:** $helm_chart" >> "$report_file"
                    echo "**Message:** $message" >> "$report_file"
                    echo "**Location:** $location" >> "$report_file"
                    echo "**Reference:** $help_uri" >> "$report_file"
                    echo "" >> "$report_file"
                fi
            done <<< "$severity_vulns"
            
            echo "---" >> "$report_file"
            echo "" >> "$report_file"
        fi
    done
    
    # Add suppressed CVEs section if any exist (optimized)
    local suppressed_data=$(jq -r --argjson suppressed_cves "$suppressed_json" '
    # Create lookup objects for rules and results  
    def rules_lookup: [.runs[0].tool.driver.rules[]] | group_by(.id) | map({
        id: .[0].id,
        severity: (
            (.[0].properties.tags[]? | select(. == "CRITICAL" or . == "HIGH" or . == "MEDIUM" or . == "LOW")) //
            (.[0].help.text? | capture("Severity: (?<sev>[A-Z]+)") | .sev) //
            "UNKNOWN"
        )
    }) | map({(.id): .}) | add;
    
    def results_lookup: [.runs[]?.results[]?] | group_by(.ruleId) | map({
        ruleId: .[0].ruleId,
        message: .[0].message.text
    }) | map({(.ruleId): .}) | add;
    
    # Build lookup tables
    rules_lookup as $rules |
    results_lookup as $results |
    
    # Get suppressed rule IDs
    [.runs[]?.results[]? | .ruleId] | unique[] |
    select(. != null and . != "") |
    select(. as $id | ($suppressed_cves | index($id)) != null) |  # Only suppressed ones
    . as $rule_id |
    {
        ruleId: $rule_id,
        severity: ($rules[$rule_id].severity // "UNKNOWN"),
        message: ($results[$rule_id].message // "No message")
    } |
    "\(.ruleId)|\(.severity)|\(.message)"
    ' "${img_dir}trivy-results.sarif" 2>/dev/null)
    
    if [ -n "$suppressed_data" ]; then
        local suppressed_count=$(echo "$suppressed_data" | wc -l | tr -d ' ')
        echo "#### 🛡️ Suppressed Vulnerabilities ($suppressed_count)" >> "$report_file"
        echo "" >> "$report_file"
        
        while IFS='|' read -r rule_id severity message; do
            if [ -n "$rule_id" ]; then
                echo "- **$rule_id** ($severity) - $message" >> "$report_file"
            fi
        done <<< "$suppressed_data"
        
        echo "" >> "$report_file"
    fi
}

# Function to validate SARIF files are available
check_sarif_files() {
    local sarif_count=0
    
    for img_dir in "$INPUT_DIR"/*/; do
        if [ -f "${img_dir}trivy-results.sarif" ]; then
            sarif_count=$((sarif_count + 1))
        fi
    done
    
    if [ $sarif_count -gt 0 ]; then
        return 0
    else
        return 1
    fi
}

# Function to generate consolidated report using SARIF data
generate_consolidated_report() {
    local report_file="$INPUT_DIR/SCAN_REPORT.md"
    local total_critical=0
    local total_high=0
    local total_medium=0
    local total_low=0
    local total_suppressed=0
    local total_failed=0

    # Validate SARIF files are available
    if ! check_sarif_files; then
        print_error "No SARIF scan result files found"
        return 1
    fi
    
    print_status "🚀 Starting consolidated report generation from SARIF data..."
    print_status "📄 Report will be saved to: $report_file"
    print_status "📝 Phase 1/4: Creating report structure..."
    echo "# Container Image Security Scan Report" > "$report_file"
    echo -e "\nGenerated on: $(date -u)" >> "$report_file"
    echo -e "\n*This report is generated from SARIF (Static Analysis Results Interchange Format) data*" >> "$report_file"
    
    # Create summary table header
    echo -e "\n## 📊 Summary Table" >> "$report_file"
    echo -e "\n| Image | 🔴 Critical | 🟠 High | 🟡 Medium | 🔵 Low | 🛡️ Suppressed | ❌ Failed |" >> "$report_file"
    echo "|-------|------------|---------|-----------|--------|--------------|-----------|" >> "$report_file"

    # First pass: collect all image data from SARIF files
    declare -A image_data
    declare -a image_names
    
    # Count total directories for progress tracking
    local total_dirs=$(find "$INPUT_DIR" -maxdepth 1 -type d | tail -n +2 | wc -l | tr -d ' ')
    local current_dir=0
    
    print_status "🔍 Phase 2/4: Analyzing SARIF files ($total_dirs images)..."
    
    for img_dir in "$INPUT_DIR"/*/; do
        current_dir=$((current_dir + 1))
        if [ -d "$img_dir" ]; then
            local img_name
            img_name=$(basename "$img_dir")
            
            # Show progress
            print_status "  [$current_dir/$total_dirs] Processing: $img_name"
            
            # Check if scan failed (no SARIF file or empty file)
            if [ ! -f "${img_dir}trivy-results.sarif" ] || [ ! -s "${img_dir}trivy-results.sarif" ]; then
                total_failed=$((total_failed + 1))
                image_data["$img_name"]="failed|-|-|-|-|-|❌"
                image_names+=("$img_name")
                continue
            fi
            
            # Count vulnerabilities from SARIF file using optimized batch counting
            local severity_counts critical high medium low
            severity_counts=$(count_all_severities_report "$img_dir")
            IFS=',' read -r critical high medium low <<< "$severity_counts"
            
            # Count suppressed vulnerabilities
            local suppressed=0
            local suppressed_json
            suppressed_json=$(printf '%s\n' "${suppressed_cves[@]}" | jq -R . | jq -s .)
            suppressed=$(count_suppressed_vulnerabilities "$img_dir" "$suppressed_json")

            # Store image data with critical count as prefix for sorting
            image_data["$img_name"]="success|$critical|$high|$medium|$low|$suppressed|-"
            image_names+=("$img_name")

            total_critical=$((total_critical + critical))
            total_high=$((total_high + high))
            total_medium=$((total_medium + medium))
            total_low=$((total_low + low))
            total_suppressed=$((total_suppressed + suppressed))
        fi
    done

    print_status "📊 Phase 3/4: Generating summary tables and sorting results..."
    
    # Sort images by critical vulnerability count (descending)
    # Create a temporary array with "critical_count:image_name" format for sorting
    declare -a sort_array
    for img_name in "${image_names[@]}"; do
        local data="${image_data[$img_name]}"
        local status=$(echo "$data" | cut -d'|' -f1)
        if [ "$status" = "failed" ]; then
            # Failed scans get -1 critical count to appear at bottom
            sort_array+=("-1:$img_name")
        else
            local critical=$(echo "$data" | cut -d'|' -f2)
            # Pad with zeros for proper numeric sorting
            printf -v padded_critical "%05d" "$critical"
            sort_array+=("$padded_critical:$img_name")
        fi
    done
    
    # Sort in descending order and extract image names
    declare -a sorted_images
    while IFS= read -r line; do
        local img_name=$(echo "$line" | cut -d':' -f2)
        sorted_images+=("$img_name")
    done < <(printf '%s\n' "${sort_array[@]}" | sort -nr)

    print_status "  ✅ Images sorted by critical vulnerability count"
    
    # Second pass: write sorted data to report
    for img_name in "${sorted_images[@]}"; do
        local data="${image_data[$img_name]}"
        local status=$(echo "$data" | cut -d'|' -f1)
        local critical=$(echo "$data" | cut -d'|' -f2)
        local high=$(echo "$data" | cut -d'|' -f3)
        local medium=$(echo "$data" | cut -d'|' -f4)
        local low=$(echo "$data" | cut -d'|' -f5)
        local suppressed=$(echo "$data" | cut -d'|' -f6)
        local failed=$(echo "$data" | cut -d'|' -f7)
        
        echo "| $img_name | $critical | $high | $medium | $low | $suppressed | $failed |" >> "$report_file"
    done

    # Add total row to summary table
    echo "|-------|------------|---------|-----------|--------|--------------|-----------|" >> "$report_file"
    echo "| **Total** | **$total_critical** | **$total_high** | **$total_medium** | **$total_low** | **$total_suppressed** | **$total_failed** |" >> "$report_file"

    # Add overall security status
    echo -e "\n## 🚨 Overall Security Status" >> "$report_file"
    echo -e "\n### Total Vulnerabilities Across All Images" >> "$report_file"
    echo "- 🔴 **Critical:** $total_critical" >> "$report_file"
    echo "- 🟠 **High:** $total_high" >> "$report_file"
    echo "- 🟡 **Medium:** $total_medium" >> "$report_file"
    echo "- 🔵 **Low:** $total_low" >> "$report_file"
    echo "- 🛡️ **Suppressed:** $total_suppressed" >> "$report_file"
    echo "- ❌ **Failed Scans:** $total_failed" >> "$report_file"

    # Add detailed summary section (using same sorting order)
    echo -e "\n## 📝 Image Summary" >> "$report_file"
    for img_name in "${sorted_images[@]}"; do
        local img_dir="$INPUT_DIR/$img_name/"
        if [ -d "$img_dir" ]; then
            # Check if scan failed (no SARIF file or empty file)
            if [ ! -f "${img_dir}trivy-results.sarif" ] || [ ! -s "${img_dir}trivy-results.sarif" ]; then
                echo -e "\n### $img_name" >> "$report_file"
                echo "- **Status:** ❌ Scan Failed" >> "$report_file"
                echo "- **Reason:** Unable to complete vulnerability scan or result file missing" >> "$report_file"
                continue
            fi
            
            local severity_counts critical high medium low
            severity_counts=$(count_all_severities_report "$img_dir")
            IFS=',' read -r critical high medium low <<< "$severity_counts"
            local suppressed_json=$(printf '%s\n' "${suppressed_cves[@]}" | jq -R . | jq -s .)
            local suppressed=$(count_suppressed_vulnerabilities "$img_dir" "$suppressed_json")

            echo -e "\n### $img_name" >> "$report_file"
            echo "- **Status:** ✅ Scan Completed" >> "$report_file"
            echo "- **Critical:** $critical" >> "$report_file"
            echo "- **High:** $high" >> "$report_file"
            echo "- **Medium:** $medium" >> "$report_file"
            echo "- **Low:** $low" >> "$report_file"
            echo "- **Suppressed:** $suppressed" >> "$report_file"
            
            # Add high-risk CVE analysis per container
            local epss_analysis=$(extract_epss_analysis "$img_dir")
            if [ -n "$epss_analysis" ]; then
                echo "$epss_analysis" >> "$report_file"
            fi
        fi
    done

    # Add detailed CVE listings
    print_status "🔍 Phase 4/4: Generating detailed CVE analysis..."
    echo -e "\n## 🔍 Detailed CVE Analysis" >> "$report_file"
    echo -e "\nThe following section lists all vulnerabilities found in each image, sorted by severity." >> "$report_file"
    echo -e "\n*Data extracted from SARIF (Static Analysis Results Interchange Format) files for standardized vulnerability reporting.*" >> "$report_file"
    
    local cve_analysis_count=0
    local total_with_sarif=0
    for img_name in "${sorted_images[@]}"; do
        local img_dir="$INPUT_DIR/$img_name/"
        if [ -d "$img_dir" ] && [ -f "${img_dir}trivy-results.sarif" ] && [ -s "${img_dir}trivy-results.sarif" ]; then
            total_with_sarif=$((total_with_sarif + 1))
        fi
    done
    
    for img_name in "${sorted_images[@]}"; do
        local img_dir="$INPUT_DIR/$img_name/"
        if [ -d "$img_dir" ] && [ -f "${img_dir}trivy-results.sarif" ] && [ -s "${img_dir}trivy-results.sarif" ]; then
            cve_analysis_count=$((cve_analysis_count + 1))
            print_status "  [$cve_analysis_count/$total_with_sarif] Analyzing CVEs for: $img_name"
            generate_detailed_cve_report "$img_name" "$img_dir" "$report_file"
        fi
    done
    
    print_status "  ✅ Completed detailed CVE analysis for $total_with_sarif images"

    # Add recommendations based on findings
    echo -e "\n## 🎯 Recommendations" >> "$report_file"
    if [ $total_failed -gt 0 ]; then
        echo "❌ **FAILED SCANS**: $total_failed images could not be scanned. Please check image accessibility and try again." >> "$report_file"
    fi
    if [ $total_critical -gt 0 ]; then
        echo "⚠️ **CRITICAL**: Immediate action required! $total_critical critical vulnerabilities found." >> "$report_file"
    fi
    if [ $total_high -gt 0 ]; then
        echo "🔴 **HIGH**: High priority action required! $total_high high vulnerabilities found." >> "$report_file"
    fi
    if [ $total_medium -gt 0 ]; then
        echo "🟡 **MEDIUM**: Plan to address $total_medium medium vulnerabilities." >> "$report_file"
    fi
    if [ $total_low -gt 0 ]; then
        echo "🟢 **LOW**: Consider addressing $total_low low vulnerabilities." >> "$report_file"
    fi
    if [ $total_suppressed -gt 0 ]; then
        echo "ℹ️ **SUPPRESSED**: $total_suppressed vulnerabilities have been suppressed based on CVE suppressions list." >> "$report_file"
    fi

    # Add information about generated files
    echo -e "\n## 📁 Files Generated" >> "$report_file"
    echo "For each scanned image, the following files are generated in its directory:" >> "$report_file"
    echo -e "\n- \`trivy-results.sarif\`: Trivy vulnerability scan results (SARIF format)" >> "$report_file"
    echo "- \`trivy-results.txt\`: Trivy vulnerability scan results (text format)" >> "$report_file"
    echo "- \`sbom.spdx.json\`: Software Bill of Materials (SPDX JSON format)" >> "$report_file"
    echo "- \`sbom.txt\`: Software Bill of Materials (text format)" >> "$report_file"
    echo "- \`summary.md\`: Per-image vulnerability summary" >> "$report_file"
    echo "- \`vulnerabilities.md\`: Detailed vulnerability report" >> "$report_file"
    echo -e "\n### 📊 SARIF Format Benefits" >> "$report_file"
    echo "- **Standardized Format**: SARIF (Static Analysis Results Interchange Format) is an industry standard" >> "$report_file"
    echo "- **Better Integration**: Compatible with GitHub Security Tab, Azure DevOps, and other platforms" >> "$report_file"
    echo "- **Rich Metadata**: Includes detailed location information and rule descriptions" >> "$report_file"
    echo "- **Interoperability**: Can be consumed by multiple security tools and dashboards" >> "$report_file"

    print_success "🎉 Consolidated SARIF-based report generated: $report_file"
    print_status "✅ All phases completed successfully!"
    
    # Print summary to console
    echo ""
    echo -e "${BLUE}┌─────────────────────────────────────────────┐${NC}"
    echo -e "${BLUE}│${NC}           📊 ${BLUE}SARIF Report Summary${NC}         ${BLUE}│${NC}"
    echo -e "${BLUE}├─────────────────────────────────────────────┤${NC}"
    echo -e "${BLUE}│${NC} 🔴 Critical vulnerabilities: ${RED}$total_critical${NC}          ${BLUE}│${NC}"
    echo -e "${BLUE}│${NC} 🟠 High vulnerabilities:     ${YELLOW}$total_high${NC}          ${BLUE}│${NC}"
    echo -e "${BLUE}│${NC} 🟡 Medium vulnerabilities:   ${YELLOW}$total_medium${NC}          ${BLUE}│${NC}"
    echo -e "${BLUE}│${NC} 🔵 Low vulnerabilities:      ${GREEN}$total_low${NC}          ${BLUE}│${NC}"
    echo -e "${BLUE}│${NC} 🛡️  Suppressed vulnerabilities: $total_suppressed     ${BLUE}│${NC}"
    echo -e "${BLUE}│${NC} ❌ Failed scans:             $total_failed          ${BLUE}│${NC}"
    echo -e "${BLUE}├─────────────────────────────────────────────┤${NC}"
    echo -e "${BLUE}│${NC} 📁 Images processed:         $total_dirs          ${BLUE}│${NC}"
    echo -e "${BLUE}│${NC} 📊 Report sections:          4 phases       ${BLUE}│${NC}"
    echo -e "${BLUE}└─────────────────────────────────────────────┘${NC}"
    echo ""
    print_status "🆕 This report now uses SARIF format for enhanced compatibility and standardization"
}

# Function to validate input directory
validate_input_dir() {
    if [ ! -d "$INPUT_DIR" ]; then
        print_error "Input directory '$INPUT_DIR' does not exist"
        print_status "Please specify a valid directory containing scan results"
        exit 1
    fi
    
    # Check if there are any scan result directories
    local scan_dirs=("$INPUT_DIR"/*/)
    if [ ${#scan_dirs[@]} -eq 0 ] || [ ! -d "${scan_dirs[0]}" ]; then
        print_error "No scan result directories found in '$INPUT_DIR'"
        print_status "The input directory should contain subdirectories with scan results"
        exit 1
    fi
    
    # Check for SARIF files
    local sarif_count=0
    for img_dir in "$INPUT_DIR"/*/; do
        if [ -f "${img_dir}trivy-results.sarif" ]; then
            sarif_count=$((sarif_count + 1))
        fi
    done
    
    if [ $sarif_count -eq 0 ]; then
        print_error "No SARIF files found in scan directories. This script requires trivy-results.sarif files."
        print_status "Make sure your scans are generating SARIF output files."
        exit 1
    fi
    
    print_status "Found $sarif_count SARIF files in input directory: $INPUT_DIR"
}

# Main execution block
main() {
    if [ "${TEST_MODE:-false}" = true ]; then
        print_status "🧪 Test mode enabled - using sample data"
    fi
    print_status "🚀 Starting SARIF-based report generation..."
    
    # Generate consolidated report
    print_status "📊 Step 4/5: Generating consolidated report..."
    generate_consolidated_report
    print_status "  ✅ Consolidated report completed"
    
    # Always update dashboard data
    print_status "🌐 Step 5/5: Updating dashboard data..."
    echo ""
    update_dashboard_data
    print_status "  ✅ Dashboard data updated"
    
    echo ""
    print_success "🎉 SARIF report generation completed successfully!"
    print_status "📊 Using SARIF (Static Analysis Results Interchange Format) data"
    print_status "🔗 Industry standard format compatible with GitHub Security, Azure DevOps, and other platforms"
    
    echo ""
    print_success "🌐 Dashboard data has been updated for GitHub Pages deployment"
    print_status "📋 Don't forget to commit and push the changes to enable the dashboard"
}

# Run main function
main
